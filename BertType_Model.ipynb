{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb4656b-7c1b-40ac-9d44-c40856d0119b",
   "metadata": {},
   "source": [
    "## Method 1\n",
    "### **`Using BERT-type models`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "083f0cba-26b2-40ea-adc5-0938df1d2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from huggingface_hub import hf_hub_download, list_repo_files\n",
    "from colorama import Style, Fore, Back\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5305c6-c21d-438b-966f-ab1bbbcb2094",
   "metadata": {},
   "source": [
    "### GET Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a66efb5-71ef-423f-90a2-b8de5c9cb1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"tabularisai/multilingual-sentiment-analysis\"\n",
    "local_dir = \"/mnt/d/Desktop/HuggingFaceModels/Multi_SA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d91fae4-d8a2-4a07-b921-e44a1272db88",
   "metadata": {},
   "source": [
    "### DO NOT RUN AGAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8bfb18c7-972d-4c11-9387-7a3e56c54cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/Desktop/HuggingFaceModels/Multi_SA/.gitattributes\n",
      "/mnt/d/Desktop/HuggingFaceModels/Multi_SA/README.md\n",
      "/mnt/d/Desktop/HuggingFaceModels/Multi_SA/config.json\n",
      "/mnt/d/Desktop/HuggingFaceModels/Multi_SA/model.safetensors\n",
      "/mnt/d/Desktop/HuggingFaceModels/Multi_SA/special_tokens_map.json\n",
      "/mnt/d/Desktop/HuggingFaceModels/Multi_SA/tokenizer.json\n",
      "/mnt/d/Desktop/HuggingFaceModels/Multi_SA/tokenizer_config.json\n",
      "/mnt/d/Desktop/HuggingFaceModels/Multi_SA/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "filenames = list_repo_files(repo_id)\n",
    "for filename in filenames:\n",
    "    print(hf_hub_download(repo_id = repo_id, local_dir = local_dir, filename=f\"{filename}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cba7e94f-52c6-4f23-b897-1912492e335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(local_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(local_dir)\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    input_text = tokenizer(text, return_tensors = \"pt\", \\\n",
    "                           padding = \"max_length\", truncation = True, max_length = 128)\n",
    "    logger.debug(f'{Style.BRIGHT}{Fore.BLUE}{input_text}{Style.RESET_ALL}')\n",
    "    with torch.no_grad():\n",
    "        output_ = model(**input_text)\n",
    "        logger.debug(f'{Style.BRIGHT}{Fore.GREEN}{output_}{Style.RESET_ALL}')\n",
    "    prob = torch.nn.functional.softmax(output_.logits, dim = -1)\n",
    "    sentiment_map = {0: \"VERY BAD\", 1: \"BAD\", 2: \"NEUTRAL\", 3: \"GOOD\", 4: \"VERY GOOD\"}\n",
    "    return [sentiment_map[p] for p in torch.argmax(prob, dim = -1).tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18444840-d04a-4df8-a258-5da265d156a3",
   "metadata": {},
   "source": [
    "### RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1a19f446-fd24-445e-869c-53b11b45d2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[1mVerdict: NEUTRAL\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[DEBUG] Everything is working properly.\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: NEUTRAL\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[INFO] Is there a reason for this happening.\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: VERY BAD\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[WARNING] This is really bad!!\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: VERY BAD\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[ERROR] Very dangerous.\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1m\u001b[32mAvg Time: 0.020964052366173786\u001b[0m\n",
      "INFO:root:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sentences = []\n",
    "with open(\"5G_logs_v2.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        sentences.append(line)\n",
    "        \n",
    "result = predict_sentiment(sentences)\n",
    "for sentence, verdict in zip(sentences, result):\n",
    "    logger.info(f\"{Style.BRIGHT}Verdict: {verdict}{Style.RESET_ALL}\")\n",
    "    logger.info(f\"{Style.BRIGHT}{Fore.BLUE}{sentence}{Style.RESET_ALL}\")\n",
    "    logger.info(f'\\n')\n",
    "end_time = time.time()\n",
    "logger.info(f'{Style.BRIGHT}{Fore.GREEN}Avg Time: {(end_time - start_time)/len(sentence)}{Style.RESET_ALL}')\n",
    "logger.info(f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fdeaf1-632b-411f-833a-116ae45a7a20",
   "metadata": {},
   "source": [
    "### RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2e7c8265-af04-46dc-8015-8718c5bd59fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[1mVerdict: NEUTRAL\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[DEBUG] Everything is working properly.\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: NEUTRAL\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[INFO] Is there a reason for this happening.\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: VERY BAD\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[WARNING] This is really bad!!\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: VERY BAD\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[ERROR] Very dangerous.\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1m\u001b[32mAvg Time: 0.017712800399116848\u001b[0m\n",
      "INFO:root:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sentences = []\n",
    "with open(\"5G_logs_v2.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        sentences.append(line)\n",
    "        \n",
    "result = predict_sentiment(sentences)\n",
    "for sentence, verdict in zip(sentences, result):\n",
    "    logger.info(f\"{Style.BRIGHT}Verdict: {verdict}{Style.RESET_ALL}\")\n",
    "    logger.info(f\"{Style.BRIGHT}{Fore.BLUE}{sentence}{Style.RESET_ALL}\")\n",
    "    logger.info(f'\\n')\n",
    "end_time = time.time()\n",
    "logger.info(f'{Style.BRIGHT}{Fore.GREEN}Avg Time: {(end_time - start_time)/len(sentence)}{Style.RESET_ALL}')\n",
    "logger.info(f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0338614-6ee2-4f71-957f-60330c848eca",
   "metadata": {},
   "source": [
    "## Method 2: caching results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a355a74b-0a28-40a1-9708-9b0f4ba14c88",
   "metadata": {},
   "source": [
    "### **`Building cache`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b5731a95-3c6b-4925-af3d-149e2802043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "filenames = glob.glob(\"*.txt\")\n",
    "versions = []\n",
    "prefix = \"5G_logs_v\"\n",
    "for filename in filenames:\n",
    "    versions.append(int(filename.split(\".\")[0][len(prefix):]))\n",
    "versions.sort()\n",
    "latest = versions[-1]\n",
    "versions.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "16326cbd-884d-405e-afa6-5d7932ba79dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache, sentence_list = defaultdict(list), []\n",
    "for filename in filenames:\n",
    "    fv = int(filename.split(\".\")[0][len(prefix):])\n",
    "    if fv != latest:\n",
    "        with open(f\"{filename}\", \"r\") as file:\n",
    "            for sentence in file:\n",
    "                sentence_list.append(sentence)\n",
    "results = predict_sentiment(sentence_list)\n",
    "for sentence, sentiment in zip(sentence_list, results):\n",
    "    insert_ = True\n",
    "    if len(cache[hash(sentence)]) != 0:\n",
    "        for sentenceX, sentiment in cache[hash(sentence)]:\n",
    "            if sentence == sentenceX:\n",
    "                insert_ = False\n",
    "                logging.debug(f\"{Style.BRIGHT}{Fore.RED}Duplicate{Style.RESET_ALL}\")\n",
    "                break\n",
    "    if insert_: cache[hash(sentence)].append((sentence, sentiment))\n",
    "\n",
    "with open(\"cache\", \"w\") as cfile:\n",
    "    json.dump(cache, cfile, indent = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56de82a-5d8f-45ae-aa9a-19019e2624f5",
   "metadata": {},
   "source": [
    "### RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0c36c8e6-2adb-478a-9475-dc6fe2e19d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[1mVerdict: NEUTRAL\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[DEBUG] Everything is working properly.\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: NEUTRAL\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[INFO] Is there a reason for this happening.\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: VERY BAD\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[WARNING] This is really bad!!\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: VERY BAD\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[ERROR] Very dangerous.\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1m\u001b[32mAvg Time: 0.012967161510301672\u001b[0m\n",
      "INFO:root:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cache = {}\n",
    "with open(\"cache\", \"r\") as cfile:\n",
    "    cache = json.load(cfile)\n",
    "\n",
    "for filename in filenames:\n",
    "    fv = int(filename.split(\".\")[0][len(prefix):])\n",
    "    if fv == latest:\n",
    "        sentence_list, sentiment_list = [], []\n",
    "        with open(f\"{filename}\", \"r\") as file:\n",
    "            for sentence in file:\n",
    "                sentence_list.append(sentence)\n",
    "        sentiment_list = [None for _ in range(len(sentence))]\n",
    "        new_list, new_list_ids = [], []\n",
    "        for idx, sentence in enumerate(sentence_list):\n",
    "            hash_key, is_new = str(hash(sentence)), True\n",
    "            if hash_key in cache:\n",
    "                for sentenceX, sentiment in cache[hash_key]:\n",
    "                    if sentence == sentenceX: \n",
    "                        sentiment_list[idx] = sentiment \n",
    "                        is_new = False\n",
    "                        break\n",
    "            if is_new: \n",
    "                new_list.append(sentence)\n",
    "                new_list_ids.append(idx)\n",
    "        new_results = predict_sentiment(new_list)\n",
    "        for ptr, ids in enumerate(new_list_ids):\n",
    "            sentiment_list[ids] = new_results[ptr]\n",
    "        break \n",
    "        \n",
    "for sentence, verdict in zip(sentence_list, sentiment_list):\n",
    "    logger.info(f\"{Style.BRIGHT}Verdict: {verdict}{Style.RESET_ALL}\")\n",
    "    logger.info(f\"{Style.BRIGHT}{Fore.BLUE}{sentence}{Style.RESET_ALL}\")\n",
    "    logger.info(f'\\n')\n",
    "\n",
    "end_time = time.time()\n",
    "logger.info(f'{Style.BRIGHT}{Fore.GREEN}Avg Time: {(end_time - start_time)/len(sentence)}{Style.RESET_ALL}')\n",
    "logger.info(f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae93af-adbf-464b-a4da-1364a1729ea2",
   "metadata": {},
   "source": [
    "### RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "76d6d464-bdb0-4b63-9259-b4b208168587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[1mVerdict: NEUTRAL\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[DEBUG] Everything is working properly.\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: NEUTRAL\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[INFO] Is there a reason for this happening.\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: VERY BAD\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[WARNING] This is really bad!!\n",
      "\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1mVerdict: VERY BAD\u001b[0m\n",
      "INFO:root:\u001b[1m\u001b[34m[ERROR] Very dangerous.\u001b[0m\n",
      "INFO:root:\n",
      "\n",
      "INFO:root:\u001b[1m\u001b[32mAvg Time: 0.01152280102605405\u001b[0m\n",
      "INFO:root:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cache = {}\n",
    "with open(\"cache\", \"r\") as cfile:\n",
    "    cache = json.load(cfile)\n",
    "\n",
    "for filename in filenames:\n",
    "    fv = int(filename.split(\".\")[0][len(prefix):])\n",
    "    if fv == latest:\n",
    "        sentence_list, sentiment_list = [], []\n",
    "        with open(f\"{filename}\", \"r\") as file:\n",
    "            for sentence in file:\n",
    "                sentence_list.append(sentence)\n",
    "        sentiment_list = [None for _ in range(len(sentence))]\n",
    "        new_list, new_list_ids = [], []\n",
    "        for idx, sentence in enumerate(sentence_list):\n",
    "            hash_key, is_new = str(hash(sentence)), True\n",
    "            if hash_key in cache:\n",
    "                for sentenceX, sentiment in cache[hash_key]:\n",
    "                    if sentence == sentenceX: \n",
    "                        sentiment_list[idx] = sentiment \n",
    "                        is_new = False\n",
    "                        break\n",
    "            if is_new: \n",
    "                new_list.append(sentence)\n",
    "                new_list_ids.append(idx)\n",
    "        new_results = predict_sentiment(new_list)\n",
    "        for ptr, ids in enumerate(new_list_ids):\n",
    "            sentiment_list[ids] = new_results[ptr]\n",
    "        break \n",
    "        \n",
    "for sentence, verdict in zip(sentence_list, sentiment_list):\n",
    "    logger.info(f\"{Style.BRIGHT}Verdict: {verdict}{Style.RESET_ALL}\")\n",
    "    logger.info(f\"{Style.BRIGHT}{Fore.BLUE}{sentence}{Style.RESET_ALL}\")\n",
    "    logger.info(f'\\n')\n",
    "\n",
    "end_time = time.time()\n",
    "logger.info(f'{Style.BRIGHT}{Fore.GREEN}Avg Time: {(end_time - start_time)/len(sentence)}{Style.RESET_ALL}')\n",
    "logger.info(f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081a384-fecf-4c14-a4a3-2a1036348b0f",
   "metadata": {},
   "source": [
    "### Expanding cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1833c761-8ea9-4ac8-8085-13495fa9fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, verdict in zip(new_list, new_results):\n",
    "    hash_key = str(hash(sentence))\n",
    "    if hash_key not in cache:\n",
    "        cache[hash_key] = []\n",
    "    cache[hash_key].append((sentence, verdict))\n",
    "\n",
    "with open(\"cache\", \"w\") as cfile:\n",
    "    json.dump(cache, cfile, indent = 5)\n",
    "    new_list, new_results = [], []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
